{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine learning of cat and dog voices - DEMO\n",
    "\n",
    "Created by [Judit Acs](https://github.com/juditacs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import wavfile\n",
    "import os\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from keras.layers import Input, Dense, Bidirectional, Dropout, Conv1D, MaxPooling1D\n",
    "from keras.layers.recurrent import LSTM, GRU\n",
    "from keras.models import Model\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data\n",
    "\n",
    "Data source on [Kaggle](https://www.kaggle.com/mmoreaux/audio-cats-and-dogs).\n",
    "\n",
    "The data is split into train and test sets. One wave file is one sample.\n",
    "\n",
    "We first load all wave files as a vector of integers into a lists of lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(125, 85)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def read_dir(dirname, X, y, label):\n",
    "    for fn in os.listdir(dirname):\n",
    "        w = wavfile.read(os.path.join(dirname, fn))\n",
    "        assert w[0] == 16000\n",
    "        X.append(w[1])\n",
    "        y.append(label)\n",
    "        \n",
    "X_train_cat = []\n",
    "y_train_cat = []\n",
    "X_test_cat = []\n",
    "y_test_cat = []\n",
    "X_train_dog = []\n",
    "y_train_dog = []\n",
    "X_test_dog = []\n",
    "y_test_dog = []\n",
    "\n",
    "read_dir(\"data/cat_dog/train/cat\", X_train_cat, y_train_cat, 1)\n",
    "read_dir(\"data/cat_dog/train/dog\", X_train_dog, y_train_dog, 0)\n",
    "read_dir(\"data/cat_dog/test/cat\", X_test_cat, y_test_cat, 1)\n",
    "read_dir(\"data/cat_dog/test/dog\", X_test_dog, y_test_dog, 0)\n",
    "\n",
    "len(X_train_cat), len(X_train_dog)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We discard some of the cat files to balance the classes, then merge the cat and dog matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85 170\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxlen = min(len(X_train_cat), len(X_train_dog))\n",
    "X_train = X_train_cat[:maxlen]\n",
    "X_train.extend(X_train_dog[:maxlen])\n",
    "y_train = y_train_cat[:maxlen]\n",
    "y_train.extend(y_train_dog[:maxlen])\n",
    "\n",
    "print(maxlen, len(X_train))\n",
    "\n",
    "maxlen = min(len(X_test_cat), len(X_test_dog))\n",
    "X_test = X_test_cat[:maxlen]\n",
    "X_test.extend(X_test_dog[:maxlen])\n",
    "y_test = y_test_cat[:maxlen]\n",
    "y_test.extend(y_test_dog[:maxlen])\n",
    "\n",
    "maxlen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract samples\n",
    "\n",
    "Wave files are too long and too few. Let's split them into smaller parts.\n",
    "\n",
    "One part is going to be 10000 sample long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_padded_mtx(list_of_lists, labels, maxlen, pad=0):\n",
    "    X = []\n",
    "    y = []\n",
    "    for i, x in enumerate(list_of_lists):\n",
    "        x_mult = np.array_split(x, x.shape[0] // maxlen)\n",
    "        for x in x_mult:\n",
    "            pad_size = maxlen-x.shape[0]\n",
    "            if pad_size > 0:\n",
    "                pad = np.zeros((maxlen-l.shape[0]))\n",
    "                x = np.concatenate((pad, l))\n",
    "            X.append(x[-maxlen:])\n",
    "        label = labels[i]\n",
    "        y.extend([label] * len(x_mult))\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "sample_len = 10000\n",
    "X_train, y_train = create_padded_mtx(X_train, y_train, sample_len)\n",
    "X_test, y_test = create_padded_mtx(X_test, y_test, sample_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scale samples\n",
    "\n",
    "Wav samples vary in a large range, we prefere values closer to zero.\n",
    "\n",
    "`StandardScaler` scales all values so that the dataset has a mean of 0 and a standard deviation of 1.\n",
    "\n",
    "Note that we fit `StandardScaler` on the train data only and use those value to transform both the train and the test matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/permanent/home/judit/miniconda3/envs/keras_deep/lib/python3.6/site-packages/sklearn/utils/validation.py:444: DataConversionWarning: Data with input dtype int16 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3.1810574671824508e-19,\n",
       " 1.0000000000000004,\n",
       " 0.0048481598994860754,\n",
       " 1.1906283629635126)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "np.mean(X_train), np.std(X_train), np.mean(X_test), np.std(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shuffle data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1778, 10000), (499, 10000))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shuf_idx = np.arange(X_train.shape[0])\n",
    "np.random.shuffle(shuf_idx)\n",
    "\n",
    "X_train = X_train[shuf_idx]\n",
    "y_train = y_train[shuf_idx]\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of unique cat and dog samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of vaus: 717\n",
      "Number of mieuws: 1061\n"
     ]
    }
   ],
   "source": [
    "cnt = np.unique(y_train, return_counts=True)[1]\n",
    "print(\"Number of vaus: {}\\nNumber of mieuws: {}\".format(cnt[0], cnt[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fully connected feed forward network\n",
    "\n",
    "## Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_layer = Input(batch_shape=(None, X_train.shape[1]))\n",
    "layer = Dense(100, activation=\"sigmoid\")(input_layer)\n",
    "# randomly disable 20% of the neurons, prevents or reduces overfitting\n",
    "layer = Dropout(.2)(layer)\n",
    "layer = Dense(100, activation=\"sigmoid\")(input_layer)\n",
    "layer = Dropout(.2)(layer)\n",
    "layer = Dense(1, activation=\"sigmoid\")(layer)\n",
    "model = Model(inputs=input_layer, outputs=layer)\n",
    "model.compile(\"rmsprop\", loss=\"binary_crossentropy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model\n",
    "\n",
    "Early stopping stops the training if validation loss does not decrease anymore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 5.48 Âµs\n",
      "Train on 1600 samples, validate on 178 samples\n",
      "Epoch 1/100\n",
      "1600/1600 [==============================] - 0s - loss: 0.8100 - val_loss: 0.7670\n",
      "Epoch 2/100\n",
      "1600/1600 [==============================] - 0s - loss: 0.4460 - val_loss: 0.8664\n",
      "Epoch 3/100\n",
      "1600/1600 [==============================] - 0s - loss: 0.3332 - val_loss: 0.9466\n",
      "Epoch 4/100\n",
      "1600/1600 [==============================] - 0s - loss: 0.2612 - val_loss: 1.0460\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f76b4f9ecc0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time\n",
    "ea = EarlyStopping(patience=2)\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=32, verbose=1, validation_split=.1, callbacks=[ea])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = model.predict(X_test)\n",
    "labels = np.round(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precision, recall and F-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dog\n",
      "===========\n",
      "prec:0.544\n",
      "rec:0.36363636363636365\n",
      "F-score:0.4358974358974359\n",
      "\n",
      "Cat\n",
      "===========\n",
      "prec:0.6818181818181818\n",
      "rec:0.8173076923076923\n",
      "F-score:0.7434402332361515\n"
     ]
    }
   ],
   "source": [
    "prec, rec, F, _ = precision_recall_fscore_support(y_test, labels)\n",
    "print(\"Dog\\n===========\\nprec:{}\\nrec:{}\\nF-score:{}\".format(prec[0], rec[0], F[0]))\n",
    "print(\"\\nCat\\n===========\\nprec:{}\\nrec:{}\\nF-score:{}\".format(prec[1], rec[1], F[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Convolutional neural network\n",
    "\n",
    "CNNs are not only good at image processing but also at handling long temporal data such as audio files.\n",
    "\n",
    "## Convert data to 3D tensors\n",
    "\n",
    "CNNs and RNNs require 3D tensors instead of 2D tensors (normal matrices).\n",
    "\n",
    "3D tensors are usually shaped as `batch_size x timestep x feature_number`, where `batch_size` is the number of samples fed to the network at once, `timestep` is the number of time steps the samples cover and `feature_number` is the dimension of the feature vectors. Audio files are one dimensional, so `feature_number` is 1.\n",
    "\n",
    "Reshaping `X_train` and `X_test`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_3d = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "X_test_3d = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# list of convolutional layers, try adding more or changing the parameters\n",
    "conv_layers = [\n",
    "    {'filters': 200, 'kernel_size': 40, 'strides': 2, 'padding': \"same\", 'activation': \"relu\"},\n",
    "    {'filters': 200, 'kernel_size': 10, 'strides': 10, 'padding': \"same\", 'activation': \"relu\"},\n",
    "    {'filters': 50, 'kernel_size': 10, 'strides': 10, 'padding': \"same\", 'activation': \"relu\"},\n",
    "]\n",
    "\n",
    "input_layer = Input(batch_shape=(None, X_train_3d.shape[1], 1))\n",
    "layer = Conv1D(**(conv_layers[0]))(input_layer)\n",
    "\n",
    "for cfg in conv_layers[1:]:\n",
    "    layer = Conv1D(**cfg)(layer)\n",
    "    layer = Dropout(.2)(layer)\n",
    "    # reduce the number of parameters\n",
    "    layer = MaxPooling1D(2, padding=\"same\")(layer)\n",
    "    \n",
    "layer = LSTM(128)(layer)\n",
    "out = Dense(1, activation=\"sigmoid\")(layer)\n",
    "\n",
    "m = Model(inputs=input_layer, outputs=out)\n",
    "\n",
    "m.compile(\"adam\", loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1600 samples, validate on 178 samples\n",
      "Epoch 1/1000\n",
      "1600/1600 [==============================] - 3s - loss: 0.6598 - val_loss: 0.5306\n",
      "Epoch 2/1000\n",
      "1600/1600 [==============================] - 1s - loss: 0.5356 - val_loss: 0.4810\n",
      "Epoch 3/1000\n",
      "1600/1600 [==============================] - 1s - loss: 0.5093 - val_loss: 0.5144\n",
      "Epoch 4/1000\n",
      "1600/1600 [==============================] - 1s - loss: 0.4817 - val_loss: 0.4504\n",
      "Epoch 5/1000\n",
      "1600/1600 [==============================] - 1s - loss: 0.4601 - val_loss: 0.5196\n",
      "Epoch 6/1000\n",
      "1600/1600 [==============================] - 1s - loss: 0.4419 - val_loss: 0.4089\n",
      "Epoch 7/1000\n",
      "1600/1600 [==============================] - 1s - loss: 0.4105 - val_loss: 0.5533\n",
      "Epoch 8/1000\n",
      "1600/1600 [==============================] - 1s - loss: 0.3979 - val_loss: 0.3502\n",
      "Epoch 9/1000\n",
      "1600/1600 [==============================] - 1s - loss: 0.3910 - val_loss: 0.4502\n",
      "Epoch 10/1000\n",
      "1600/1600 [==============================] - 1s - loss: 0.3702 - val_loss: 0.3328\n",
      "Epoch 11/1000\n",
      "1600/1600 [==============================] - 1s - loss: 0.3450 - val_loss: 0.3007\n",
      "Epoch 12/1000\n",
      "1600/1600 [==============================] - 1s - loss: 0.3325 - val_loss: 0.4008\n",
      "Epoch 13/1000\n",
      "1600/1600 [==============================] - 1s - loss: 0.3329 - val_loss: 0.2917\n",
      "Epoch 14/1000\n",
      "1600/1600 [==============================] - 1s - loss: 0.3100 - val_loss: 0.4271\n",
      "Epoch 15/1000\n",
      "1600/1600 [==============================] - 1s - loss: 0.2991 - val_loss: 0.2924\n",
      "Epoch 16/1000\n",
      "1600/1600 [==============================] - 1s - loss: 0.2621 - val_loss: 0.2844\n",
      "Epoch 17/1000\n",
      "1600/1600 [==============================] - 1s - loss: 0.2540 - val_loss: 0.2855\n",
      "Epoch 18/1000\n",
      "1600/1600 [==============================] - 1s - loss: 0.2581 - val_loss: 0.2818\n",
      "Epoch 19/1000\n",
      "1600/1600 [==============================] - 1s - loss: 0.2454 - val_loss: 0.2505\n",
      "Epoch 20/1000\n",
      "1600/1600 [==============================] - 1s - loss: 0.2266 - val_loss: 0.2719\n",
      "Epoch 21/1000\n",
      "1600/1600 [==============================] - 1s - loss: 0.2298 - val_loss: 0.2587\n",
      "Epoch 22/1000\n",
      "1600/1600 [==============================] - 1s - loss: 0.2109 - val_loss: 0.2666\n",
      "CPU times: user 30.8 s, sys: 3.34 s, total: 34.1 s\n",
      "Wall time: 40 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ea = EarlyStopping(patience=2)\n",
    "hist = m.fit(X_train_3d, y_train, epochs=1000, batch_size=128, validation_split=.1, callbacks=[ea])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = m.predict(X_test_3d)\n",
    "labels = (pred > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dog\n",
      "===========\n",
      "prec:0.912568306010929\n",
      "rec:0.893048128342246\n",
      "F-score:0.9027027027027028\n",
      "\n",
      "Cat\n",
      "===========\n",
      "prec:0.9367088607594937\n",
      "rec:0.9487179487179487\n",
      "F-score:0.9426751592356688\n"
     ]
    }
   ],
   "source": [
    "prec, rec, F, _ = precision_recall_fscore_support(y_test, labels)\n",
    "print(\"Dog\\n===========\\nprec:{}\\nrec:{}\\nF-score:{}\".format(prec[0], rec[0], F[0]))\n",
    "print(\"\\nCat\\n===========\\nprec:{}\\nrec:{}\\nF-score:{}\".format(prec[1], rec[1], F[1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
